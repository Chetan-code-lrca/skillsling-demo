import streamlit as st
import ollama
import time
import tempfile
import os
import json
from datetime import datetime
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

# ==================== CONFIG ====================
AVAILABLE_MODELS = ["llama3.2:3b", "gemma2:2b", "phi3:mini"]

PLACEHOLDERS = {
    "Hindi": "‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç...",
    "English": "Type your question here...",
    "Hinglish": "Apna sawaal yahan likhein...",
    "Tamil": "‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡ÆØ‡Øà ‡Æá‡Æô‡Øç‡Æï‡Øá ‡Æé‡Æ¥‡ØÅ‡Æ§‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç...",
    "Telugu": "‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø..."
}

# ULTRA-STRONG LANGUAGE ENFORCEMENT
LANGUAGE_SYSTEM_PROMPTS = {
    "Hindi": """‡§§‡•Å‡§Æ ‡§è‡§ï ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∂‡§ø‡§ï‡•ç‡§∑‡§ï ‡§π‡•ã‡•§
‡§Ö‡§®‡§ø‡§µ‡§æ‡§∞‡•ç‡§Ø ‡§®‡§ø‡§Ø‡§Æ (3 ‡§¨‡§æ‡§∞ ‡§¶‡•ã‡§π‡§∞‡§æ‡§ì):
1. ‡§ï‡•á‡§µ‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§≤‡§ø‡§™‡§ø ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•ã‡•§ ‡§ï‡•á‡§µ‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç‡•§ ‡§ï‡•á‡§µ‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç‡•§
2. ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§Ö‡§ï‡•ç‡§∑‡§∞, ‡§∂‡§¨‡•ç‡§¶, ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§Æ‡§§ ‡§≤‡§ø‡§ñ‡•ã ‚Äì ‡§è‡§ï ‡§≠‡•Ä ‡§®‡§π‡•Ä‡§Ç‡•§
3. ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§≠‡•Ä ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§ì‡•§
4. ‡§∏‡§∞‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•ã‡•§
5. ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§ï‡•ã ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§∞‡•ã‡•§
‡§ó‡§≤‡§§ ‡§â‡§¶‡§æ‡§π‡§∞‡§£: "Photosynthesis is..."
‡§∏‡§π‡•Ä ‡§â‡§¶‡§æ‡§π‡§∞‡§£: "‡§™‡•ç‡§∞‡§ï‡§æ‡§∂ ‡§∏‡§Ç‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§è‡§ï ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§π‡•à..."
NCERT ‡§¶‡§ø‡§∂‡§æ-‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡§æ ‡§™‡§æ‡§≤‡§® ‡§ï‡§∞‡•ã‡•§""",
    
    "English": """You are an English tutor for Indian students.
MANDATORY RULES (repeat 3 times):
1. Respond ONLY in English language. ONLY in English. ONLY in English.
2. Use simple, clear English words.
3. Explain concepts in an easy-to-understand manner.
4. Encourage the student positively.
5. Follow NCERT curriculum guidelines.
Wrong example: "‡§´‡•ã‡§ü‡•ã‡§∏‡§ø‡§Ç‡§•‡•á‡§∏‡§ø‡§∏ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?"
Correct example: "Photosynthesis is the process by which plants make their own food using sunlight..."
Answer only what is asked.""",
    
    "Hinglish": """Tum ek Hinglish tutor ho (Roman script mein Hindi + English mix).
MANDATORY RULES (repeat 3 times):
1. Hindi aur English mix karke likhna hai. ONLY Roman script.
2. Devanagari mat use karo.
3. Simple words use karo.
4. Student ko encourage karo.
Sirf jo pucha hai wahi jawab do.
Example: "Photosynthesis kya hai?" ‚Üí "Photosynthesis ek process hai jisme plants sunlight se khana banate hain..." """,
    
    "Tamil": """‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æí‡Æ∞‡ØÅ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡ÆÜ‡Æö‡Æø‡Æ∞‡Æø‡ÆØ‡Æ∞‡Øç.
‡Æï‡Æü‡Øç‡Æü‡Ææ‡ÆØ ‡Æµ‡Æø‡Æ§‡Æø‡Æï‡Æ≥‡Øç (3 ‡ÆÆ‡ØÅ‡Æ±‡Øà ‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç):
1. ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡Æé‡Æ¥‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Æ≥‡Æø‡Æ≤‡Øç ‡ÆÆ‡Æü‡Øç‡Æü‡ØÅ‡ÆÆ‡Øá ‡Æ™‡Æ§‡Æø‡Æ≤‡Æ≥‡Æø‡Æï‡Øç‡Æï ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç. ‡ÆÆ‡Æü‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æø‡Æ≤‡Øç. ‡ÆÆ‡Æü‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æø‡Æ≤‡Øç.
2. ‡ÆÜ‡Æô‡Øç‡Æï‡Æø‡Æ≤ ‡Æé‡Æ¥‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Æ≥‡Øç ‡Æ™‡ÆØ‡Æ©‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡Ææ‡ÆÆ‡Øç.
3. ‡Æé‡Æ≥‡Æø‡ÆØ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡Æö‡Øä‡Æ±‡Øç‡Æï‡Æ≥‡Øà‡Æ™‡Øç ‡Æ™‡ÆØ‡Æ©‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æµ‡ØÅ‡ÆÆ‡Øç.
4. ‡ÆÆ‡Ææ‡Æ£‡Æµ‡Æ∞‡Øà ‡Æä‡Æï‡Øç‡Æï‡ØÅ‡Æµ‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.
‡Æ§‡Æµ‡Æ±‡Ææ‡Æ© ‡Æâ‡Æ§‡Ææ‡Æ∞‡Æ£‡ÆÆ‡Øç: "Photosynthesis is..."
‡Æö‡Æ∞‡Æø‡ÆØ‡Ææ‡Æ© ‡Æâ‡Æ§‡Ææ‡Æ∞‡Æ£‡ÆÆ‡Øç: "‡Æí‡Æ≥‡Æø‡Æö‡Øç‡Æö‡Øá‡Æ∞‡Øç‡Æï‡Øç‡Æï‡Øà ‡Æé‡Æ©‡Øç‡Æ™‡Æ§‡ØÅ..." """,
    
    "Telugu": """‡∞Æ‡±Ä‡∞∞‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞â‡∞™‡∞æ‡∞ß‡±ç‡∞Ø‡∞æ‡∞Ø‡±Å‡∞≤‡±Å.
‡∞§‡∞™‡±ç‡∞™‡∞®‡∞ø‡∞∏‡∞∞‡∞ø ‡∞®‡∞ø‡∞Ø‡∞Æ‡∞æ‡∞≤‡±Å (3 ‡∞∏‡∞æ‡∞∞‡±ç‡∞≤‡±Å ‡∞™‡±Å‡∞®‡∞∞‡∞æ‡∞µ‡±É‡∞§‡∞Ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø):
1. ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞≤‡∞ø‡∞™‡∞ø‡∞≤‡±ã ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞æ‡∞≤‡∞ø. ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã. ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã.
2. ‡∞Ü‡∞Ç‡∞ó‡±ç‡∞≤ ‡∞Ö‡∞ï‡±ç‡∞∑‡∞∞‡∞æ‡∞≤‡±Å ‡∞µ‡∞æ‡∞°‡∞ï‡±Ç‡∞°‡∞¶‡±Å.
3. ‡∞∏‡±Å‡∞≤‡∞≠‡∞Æ‡±à‡∞® ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞™‡∞¶‡∞æ‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.
4. ‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ‡∞∞‡±ç‡∞•‡∞ø‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡±ã‡∞§‡±ç‡∞∏‡∞π‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.
‡∞§‡∞™‡±ç‡∞™‡±Å ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£: "Photosynthesis is..."
‡∞∏‡∞∞‡±à‡∞® ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£: "‡∞ï‡∞æ‡∞Ç‡∞§‡∞ø ‡∞∏‡∞Ç‡∞∂‡±ç‡∞≤‡±á‡∞∑‡∞£ ‡∞Ö‡∞®‡±á‡∞¶‡∞ø..." """
}

# ==================== PAGE CONFIG ====================
st.set_page_config(
    page_title="SkillSling - AMD Slingshot 2026",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="collapsed"   # Mobile-first: sidebar collapsed by default
)

# ==================== PWA + PROFESSIONAL DARK UI + MOBILE RESPONSIVE ====================
st.markdown("""
    <style>
    /* Your beautiful dark AMD theme */
    .stApp {
        background: linear-gradient(135deg, #0b0d11 0%, #1a1d23 100%);
        color: #e3e3e3;
    }
    
    section[data-testid="stSidebar"] {
        background-color: #111216 !important;
        border-right: 2px solid #ed1c24;
    }
    
    .stChatMessage {
        border-radius: 12px;
        padding: 1.2rem;
        margin-bottom: 0.8rem;
        box-shadow: 0 2px 8px rgba(0,0,0,0.3);
    }
    
    [data-testid="stChatMessageUser"] {
        background: linear-gradient(135deg, #1e2028 0%, #2a2d35 100%) !important;
        border-left: 4px solid #ed1c24;
    }
    
    [data-testid="stChatMessageAssistant"] {
        background: linear-gradient(135deg, #1a1d24 0%, #23252e 100%) !important;
        border-left: 4px solid #00ff88;
    }
    
    .amd-badge {
        background: linear-gradient(90deg, #ed1c24 0%, #ff4444 100%);
        padding: 8px 16px;
        border-radius: 20px;
        font-size: 0.75rem;
        font-weight: bold;
        color: white;
        text-transform: uppercase;
        border: 2px solid #ff0000;
        display: inline-block;
        margin: 5px 0;
        box-shadow: 0 0 20px rgba(237, 28, 36, 0.5);
    }
    
    .perf-metric {
        font-size: 0.7rem;
        opacity: 0.6;
        font-family: 'Courier New', monospace;
        margin-top: 8px;
        padding: 4px 8px;
        background: rgba(0, 255, 136, 0.1);
        border-radius: 4px;
        display: inline-block;
    }
    
    #MainMenu, footer {visibility: hidden;}
    
    /* MOBILE RESPONSIVE ‚Äì fixes sidebar and input */
    @media (max-width: 768px) {
        section[data-testid="stSidebar"] {
            min-width: 0 !important;
            width: 0 !important;
            visibility: hidden !important;
            overflow: hidden !important;
            transition: all 0.3s ease;
        }
        
        section[data-testid="stSidebar"][aria-expanded="true"] {
            min-width: 85vw !important;
            width: 85vw !important;
            visibility: visible !important;
            z-index: 1000 !important;
            position: fixed !important;
            top: 0 !important;
            left: 0 !important;
            height: 100vh !important;
            overflow-y: auto !important;
            box-shadow: 2px 0 15px rgba(0,0,0,0.6);
        }
        
        .stChatInput {
            padding-bottom: 100px !important;
            position: fixed !important;
            bottom: 0 !important;
            left: 0 !important;
            right: 0 !important;
            background: #0b0d11 !important;
            z-index: 999 !important;
            box-shadow: 0 -4px 12px rgba(0,0,0,0.5);
        }
        
        .main .block-container {
            padding-bottom: 140px !important;
        }
        
        .stChatMessage {
            font-size: 16px !important;
            padding: 0.8rem !important;
        }
        
        h1 { font-size: 1.8rem !important; }
        h2, h3 { font-size: 1.4rem !important; }
    }
    </style>
""", unsafe_allow_html=True)

# ==================== PWA (Installable on Phone) ====================
st.markdown("""
    <link rel="manifest" href="data:application/manifest+json;base64,eyJuYW1lIjoiU2tpbGxTbGluZyIsInNob3J0X25hbWUiOiJTa2lsbFNsaW5nIiwic3RhcnRfdXJsIjoiLiIsImRpc3BsYXkiOiJzdGFuZGFsb25lIiwiYmFja2dyb3VuZF9jb2xvciI6IiMwYjBkMTEiLCJ0aGVtZV9jb2xvciI6IiNlZDFjMjQifQ==" />
    <meta name="theme-color" content="#ed1c24">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
""", unsafe_allow_html=True)

# ==================== SESSION STATE ====================
if "messages" not in st.session_state:
    st.session_state.messages = []
if "subject" not in st.session_state:
    st.session_state.subject = "General"
if "language" not in st.session_state:
    st.session_state.language = "English"
if "model" not in st.session_state:
    st.session_state.model = AVAILABLE_MODELS[0]
if "vector_store" not in st.session_state:
    st.session_state.vector_store = None
if "total_inference_time" not in st.session_state:
    st.session_state.total_inference_time = 0
if "query_count" not in st.session_state:
    st.session_state.query_count = 0
if "last_language" not in st.session_state:
    st.session_state.last_language = "English"
if "language_change_counter" not in st.session_state:
    st.session_state.language_change_counter = 0

# ==================== SIDEBAR ====================
with st.sidebar:
    st.markdown("""
        <div style='text-align: center; margin-bottom: 20px;'>
            <h1 style='color: #ed1c24; margin-bottom: 5px;'>SKILLSLING</h1>
            <div class='amd-badge'>‚ö° AMD SLINGSHOT 2026</div>
            <p style='font-size: 0.75rem; opacity: 0.7; margin-top: 10px;'>
                Offline AI Tutor | 100% Local Inference
            </p>
        </div>
    """, unsafe_allow_html=True)

    # Light hybrid badge
    st.markdown("""
        <div class='amd-badge' style='margin: 10px 0;'>
            Offline Mode ‚Äì AMD Powered
        </div>
    """, unsafe_allow_html=True)

    # Ollama status
    try:
        ollama.list()
        st.success("‚úÖ Ollama Running")
    except:
        st.error("‚ùå Ollama Not Running!")
        st.caption("Start Ollama: `ollama serve`")
    st.markdown("---")

    # Language selection
    st.subheader("üåê Language")
    new_language = st.selectbox(
        "Choose your preferred language",
        ["English", "Hindi", "Hinglish", "Tamil", "Telugu"],
        index=["English", "Hindi", "Hinglish", "Tamil", "Telugu"].index(st.session_state.language)
    )
    
    if new_language != st.session_state.language:
        st.session_state.language = new_language
        st.session_state.last_language = new_language
        st.session_state.language_change_counter += 1
        st.rerun()

    # Subject & Model
    st.subheader("üìö Subject")
    st.session_state.subject = st.selectbox("Select your subject", ["General", "Mathematics", "Science", "English", "Social Science"], index=0)

    st.subheader("ü§ñ AI Model")
    st.session_state.model = st.selectbox("Select AI model", AVAILABLE_MODELS, index=0)

    # PDF upload
    st.subheader("üìÑ Study Material")
    use_pdf = st.checkbox("Use uploaded PDF context", value=False)
    uploaded_file = st.file_uploader("Upload your notes (PDF)", type="pdf")

    if uploaded_file is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        with st.spinner("üîÑ Processing PDF..."):
            try:
                loader = PyPDFLoader(tmp_path)
                docs = loader.load()
                splits = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100).split_documents(docs)
                st.session_state.vector_store = FAISS.from_documents(splits, OllamaEmbeddings(model=st.session_state.model))
                st.success(f"‚úÖ PDF processed ({len(docs)} pages)")
            except Exception as e:
                st.error(f"‚ùå PDF processing failed: {str(e)}")
        os.unlink(tmp_path)

    st.markdown("---")

    # Performance
    if st.session_state.query_count > 0:
        avg_time = st.session_state.total_inference_time / st.session_state.query_count
        st.subheader("üìä Performance")
        st.metric("Queries Processed", st.session_state.query_count)
        st.metric("Avg Response Time", f"{avg_time:.2f}s")
        st.metric("Total Inference", f"{st.session_state.total_inference_time:.1f}s")

    st.markdown("---")

    if st.button("üóëÔ∏è Clear Chat", use_container_width=True):
        st.session_state.messages = []
        st.session_state.total_inference_time = 0
        st.session_state.query_count = 0
        st.rerun()

    if st.button("üíæ Export Chat (JSON)", use_container_width=True):
        if st.session_state.messages:
            chat_data = {
                "export_time": datetime.now().isoformat(),
                "language": st.session_state.language,
                "model": st.session_state.model,
                "subject": st.session_state.subject,
                "messages": st.session_state.messages
            }
            st.download_button(
                "Download JSON",
                json.dumps(chat_data, ensure_ascii=False, indent=2),
                file_name=f"skillsling_chat_{int(time.time())}.json",
                mime="application/json"
            )

    st.markdown("---")
    st.caption("Built by SkillSling Team")
    st.caption("Powered by AMD GPUs")

# ==================== MAIN CONTENT ====================
if not st.session_state.messages:
    st.markdown("""
        <div style='text-align:center; padding: 60px 20px;'>
            <h1 style='color:#ed1c24; font-size: 3rem; margin-bottom: 10px;'>üöÄ SkillSling AI</h1>
            <p style='font-size: 1.2rem; opacity: 0.8; margin-bottom: 30px;'>Your Offline Intelligent Tutor</p>
            <div class='amd-badge' style='font-size: 0.9rem;'>‚ö° POWERED BY AMD SLINGSHOT</div>
            <p style='margin-top: 30px; font-size: 0.95rem; opacity: 0.7;'>
                ‚Ä¢ Multi-language support (5 languages)<br>
                ‚Ä¢ 100% offline & private<br>
                ‚Ä¢ PDF note integration<br>
                ‚Ä¢ NCERT-aligned responses
            </p>
        </div>
    """, unsafe_allow_html=True)

# Chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg["role"] == "assistant" and "latency" in msg:
            st.markdown(f"<div class='perf-metric'>‚ö° {msg['latency']:.2f}s | AMD Optimized</div>", unsafe_allow_html=True)

# Dynamic placeholder + force re-mount
current_placeholder = PLACEHOLDERS.get(st.session_state.language, "Type your question...")
prompt = st.chat_input(
    current_placeholder,
    key=f"chat_input_{st.session_state.language}_{st.session_state.get('language_change_counter', 0)}"
)

# ==================== CHAT LOGIC ====================
if prompt:
    print(f"DEBUG: INPUT CAPTURED! Prompt: '{prompt}' | Language: {st.session_state.language} | Model: {st.session_state.model}")

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = ""

        ollama_messages = []
        language_prompt = LANGUAGE_SYSTEM_PROMPTS.get(st.session_state.language, LANGUAGE_SYSTEM_PROMPTS["English"])
        ollama_messages.append({"role": "system", "content": f"{language_prompt}\n\nSubject Focus: {st.session_state.subject}"})

        if len(st.session_state.messages) == 2:  # First user message
            ollama_messages.append({"role": "user", "content": f"Important: From now on reply ONLY in {st.session_state.language}. No English at all. Start now."})

        for msg in st.session_state.messages:
            ollama_messages.append(msg)

        start_time = time.time()
        with st.spinner(f"ü§î Thinking in {st.session_state.language}..."):
            try:
                stream = ollama.chat(model=st.session_state.model, messages=ollama_messages, stream=True)
                for chunk in stream:
                    if 'message' in chunk and 'content' in chunk['message']:
                        full_response += chunk['message']['content']
                        placeholder.markdown(full_response + "‚ñå")
                        time.sleep(0.01)
                placeholder.markdown(full_response)
                latency = time.time() - start_time

                st.session_state.total_inference_time += latency
                st.session_state.query_count += 1

                st.markdown(f"<div class='perf-metric'>‚ö° {latency:.2f}s | AMD Optimized</div>", unsafe_allow_html=True)

                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response,
                    "latency": latency,
                    "timestamp": datetime.now().isoformat()
                })
            except Exception as e:
                st.error(f"Error: {str(e)}")
                placeholder.markdown("Sorry bhai, kuch gadbad ho gayi. Ollama chal raha hai?")

st.caption("Pro Tip: Change language anytime ‚Äì your chat history stays preserved!")